
# 概述 #
## 价值 ##
解耦合
数据持久化
扩展与容灾
顺序保证
缓冲&峰值处理能力
异步通信

## 核心概念 ##（注意区分逻辑概念和物理概念，这部分自己之后独立修改）
**消息**： 最基本数据单元，包含key和value，均为byte数组，key主要是根据一定的策略，将此消息路由到指定的分区
**Topic**: 用于存储消息的逻辑概念，可以看做一个消息集合，每个Topic可以有多个生产者向其中推送消息，也可以有任意多个消费者来消费消息。
**分区Partition**: 每一个Topic可以划分为多个分区，同一个Topic下的不同分区包含的消息不同。每个消息在被添加到分区时，都会被分配一个offset，它是消息在此分区中的唯一编号，kafka通过offset保证消息在分区内的顺序，Kafka通过offset保证消息在分区内的顺序，offset不跨分区，即Kafka保证在同一个分区内的消息是有序的。
同一个Topic的不同分区会被分配到不同的broker，分区时Kafka水平扩展的基础，可以通过添加服务器并在骑上分配分区来增加kafka并行处理能力。
**Log**：分区逻辑上对应一个Log，当生产者将消息写入分区，实际上写入了分区的Log。Log是一个逻辑概念，对应磁盘上的一个文件夹，Log由多个Segment组成，每个对应一个**日志文件或索引文件（稀疏索引）**，在面对海量数据时，为了避免出现超大文件，每个日志文件的大小是有限制的。

**保留策略Retention Policy**： 无论消费者是否消费了消息，Kafka会一致保存，但不会像数据库那样长期保存，当保存超过指定时间就会被删除，另一种是根据Topic存储的数据大小，当Topic的数据大小大于某个阈值则开始删除最旧的数据。Kafka会启动一个后台线程定期处理。
**日志压缩Log Compaction**：把数据的历史记录合并，只保留最新的数据的日志。

**Broker**：在生产环境，一般对应一台物理服务器，主要工作时接受生产者发来的消息，分配offset，之后保存在磁盘；同时接受消费者或者其他Broker的请求，根据请求类型进行相应处理并返回响应。

**副本**：Kafka对消息进行冗余备份，每个Partition可以有多个副本，每个服务中包含的消息是一样的。每个分区的副本集合中，都会选举出一个副本作为Leader副本，Kafka在不同场景采用不同选举策略。

**ISR集合**:In-Sync **Replica集合表示的是目前可用的且消息量与Leader相差不多的副本集合**，这是整个副本集合的一个子集。特点：副本所在节点必须维持和ZooKeeper的连接；副本最后一条消息offset与Leader副本的最后一条消息的offset之间的差值不超过指定的阈值。

**HW&LEO**：**HighWatermark**和LEO与上面的ISR集合紧密相关，其标记了一个特殊的offset，当消费者处理消息时，就只能拉去到HW之前的消息，之后的消息对消费者不可见（思考一下这个模型）。与ISR集合类似，其由Leader副本管理，当ISR集合中全部的follower副本都拉去HW指定消息进行同步后，Leader副本才会递增HW的值，Kafka将HW之前的消息状态称为"commit"，其含义是这些消息在多个副本中同时存在，即使此时Leader副本损坏，也不会出现数据丢失。
**LEO**(Log End Offset)是所有副本都会有的一个offset标记，它指向追加到当前副本的最后一个消息的offset。
同步复制和异步复制的概念
Kafka权衡了同步复制和异步复制两种策略，通过引入ISR集合，巧妙的解决了以上方案的缺陷：当Follower副本延迟高时被剔除，消息仍然可以快速提交，生产者可以快速得到响应，避免高延时的Follower副本影响整个集群的性能。当leader副本所在Broker突然宕机时，会优先将ISR集合中Follower副本选为Leader副本，新Leader副本包含了HW之前的全部信息，这就避免了消息的丢失。

**Cluster&Controller**：多个Broker组成一个Cluster对外提供服务，每个Cluster将选举出一个Broker来担任Controller，其复制管理分区副本状态、监听Zookeeper中数据的变化。

**生产者**：生产消息并按照一定规则推送到Topic的分区中，Key的Hash选择分区。
**消费者**：消费者负责从Topic拉去消息并消费，某个消费者消费到Partition的那个位置的相关信息，由Consumer维护。
**ConsumerGroup**：组合了队列和发布-订阅模式。

# Producer #


# Server #



# Consumer #



# 工具 #







Tip:
**稀疏索引**
索引项中只对应主文件中的部分记录，即不会给每条记录建立索引。
稀疏索引要求索引字段选自于主文件中的有序属性(即属性值是按照递增排序的)，如上图所示，索引字段选自于公寓名称，而公寓名称是按照字母进行排序的。
查询方式
如果要查找某条记录K，先从索引表找，如果未找到，则找相邻的小于K的最大索引字段值对应的索引项，然后从该索引项对应的记录开始顺序进行Table检索。拿上图来说，我们要找Donwtown所在的记录，但是在索引表中未找到对应的索引项，那么我们已知比Downtown小的是Brighton，我们可以从Brighton对应的记录开始查询，这样就提高了查询效率。
**稠密索引**
对于主文件中每一条记录都有索引项与之对应，因此有可能一个索引项会对应多个记录。
稠密索引分为以下三种：
候选键属性的稠密索引
因为使用候选键作为索引字段，所以稠密索引很好建立
属性值可重复的稠密索引
第一种是要求索引字段值不能重复，主文件记录按搜索码排序
由于索引字段值不能重复，但选取的属性可重复取相同的值，所以要求主文件中的记录需要排序。当我们从索引中找到对应的记录后，再从主文件中按顺序查找，就可以找到想要的记录了。
第二种是要求搜索字段不能重复，主文件记录无序
如同所示引入指针桶，先通过索引找到对应的指针桶，然后从指针桶找对应的记录。




**参考文献**
1. 徐郡明. Apache Kafka源码剖析[M]. 北京:电子工业出版社, 2017.时